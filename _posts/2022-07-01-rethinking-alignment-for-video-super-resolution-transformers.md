---
layout: post
tags: Video Super-Resolution
authors: "Shuwei Shi<sup>*</sup>, <a href='http://www.jasongt.com/'>Jinjin Gu<sup>*</sup></a>, Liangbin Xie, <a href='https://xinntao.github.io'>Xintao Wang<sup>*</sup></a>, Yujiu Yang, <a href='https://xpixel.group/index.html'>Chao Dong</a>"
venue: "Neural Information Processing Systems (<b>NeurIPS</b>), 2022"
date: 2022-07-01 00:00
thumbnail: /assets/img/psrt/web_cover.png
title: Rethinking Alignment in Video Super-Resolution Transformers
permalink: /psrt.html
published: true
---

Our experiments show that: (i) VSR Transformers can directly utilize multi-frame information from unaligned videos, and (ii) existing alignment methods are sometimes harmful to VSR Transformers. we propose a new and efficient alignment method called patch alignment, which aligns image patches instead of pixels. VSR Transformers equipped with patch alignment could demonstrate SoTA performance.

<!--more-->


### Resources
<!-- - Paper (CVPR 2021) -->
- [Newest Version (arXiv)](https://arxiv.org/pdf/2207.08494.pdf)
- Video [[Bilibili]](https://www.bilibili.com/video/BV14T411u7go?share_source=copy_web&vd_source=fe50f7167cf7a6d37e439cef26fcaf81)
- [Code](https://github.com/XPixelGroup/RethinkVSRAlignment)

### Citation
If you find our work inspiring, please cite our work:

```
@article{shi2022rethinking,
  title={Rethinking Alignment in Video Super-Resolution Transformers},
  author={Shi, Shuwei and Gu, Jinjin and Xie, Liangbin and Wang, Xintao and Yang, Yujiu and Dong, Chao},
  journal={Advances in Neural Information Processing Systems},
  year={2022}
}
```

