I"h<p>SR networks are mysterious and little works make attempt to understand them. In this work, we perform attribution analysis of SR networks, which aims at finding the input pixels that strongly influence the SR results. We propose a novel attribution approach called local attribution map (LAM) to interpret SR networks. Our work opens new directions for designing SR networks and interpreting low-level vision deep models.</p>

<!--more-->

<h3 id="local-attribution-maps-lam">Local Attribution Maps (LAM)</h3>

<p>LAM is build based on the following <strong>Auxiliary Principles</strong>:</p>
<ol>
  <li>Interpreting local not global.</li>
  <li>Interpreting hard not simple.</li>
  <li>Interpreting features not pixels.</li>
</ol>

<p>The framework of LAM:</p>
<div style="text-align: center;">
<img src="/assets/img/lam/web_framework.png" alt="framework" style="border: none; width: 75%; align: center" class="pull-center img-responsive thumb img-thumbnail" />
</div>

<p>LAM inherits the integral gradient method yet with two unique features.</p>
<ol>
  <li>We use the blurred image as the baseline input.</li>
  <li>We adopt a novel progressive blurring function as the path function.</li>
</ol>

<h3 id="results">Results</h3>

<div style="text-align: center;">
<img src="/assets/img/lam/web_lam_results.png" alt="framework" style="border: none; width: 100%; align: center" class="pull-center img-responsive thumb img-thumbnail" />
</div>

<h3 id="interesting-findings">Interesting Findings</h3>
<p>Based on LAM, we have several interesting conclusions:</p>
<ol>
  <li>SR networks with a wider range of involved input pixels could achieve better performance.</li>
  <li>Attention networks and non-local networks extract features from a wider range of input pixels.</li>
  <li>Comparing with the range that actually contributes, the receptive field is large enough for most deep networks.</li>
  <li>For SR networks, textures with regular stripes or grids are more likely to be noticed, while complex semantics are difficult to utilize.</li>
</ol>

<div style="text-align: center;">
<img src="/assets/img/lam/web_area_of_interest.png" alt="framework" style="border: none; width: 100%; align: center" class="pull-center img-responsive thumb img-thumbnail" />
</div>

<p>More information please refer to our paper.</p>

<h3 id="try-our-online-demo-on-colab">Try Our Online Demo on Colab!</h3>

<p>We build an online demo hosted on Google Colab. You can try LAM attribution results to see its interesting results.</p>

<div style="text-align: center;">
<img src="/assets/img/lam/lam_web.gif" alt="framework" style="width: 100%; align: center" class="pull-center img-responsive thumb img-thumbnail" />
</div>

<p><a href="https://colab.research.google.com/drive/1ZodQ8CRCfHw0y6BweG9zB3YrK_lYWcDk?usp=sharing">Try Here!</a></p>

<h3 id="resources">Resources</h3>
<!-- - Paper (CVPR 2021) -->
<ul>
  <li><a href="">Paper CVPR2021</a></li>
  <li><a href="https://arxiv.org/abs/2011.11036">Technical Report (arXiv)</a></li>
  <li><a href="assets/pdfs/LAM-full-resolution.pdf">Technical Report (Full resolution, 50Mb)</a></li>
  <li><a href="https://colab.research.google.com/drive/1ZodQ8CRCfHw0y6BweG9zB3YrK_lYWcDk?usp=sharing">Colab Demo</a></li>
  <li>Code on GitHub (Coming soon)</li>
</ul>

<h3 id="citation">Citation</h3>
<p>If you find our work inspiring, please cite our work:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@article{gu2020interpreting,
  title   = {Interpreting Super-Resolution Networks with Local Attribution Maps},
  author  = {Gu, Jinjin and Dong, Chao},
  year    = {2020}
}
</code></pre></div></div>
:ET